"""SQLite-backed repository for training plans.

Replaces the in-memory `_plans_storage: Dict[str, Dict[str, Any]] = {}` from routes/plans.py
with persistent storage in SQLite, enabling:
- Data persistence across server restarts
- Concurrent access safety
- Support for horizontal scaling
"""

import json
import sqlite3
from datetime import datetime, date
from pathlib import Path
from typing import Optional, List, Dict, Any
from contextlib import contextmanager

from .base import Repository
from ...models.plans import (
    TrainingPlan,
    TrainingWeek,
    PlannedSession,
    RaceGoal,
    PlanConstraints,
    AthleteContext,
    PeriodizationType,
    TrainingPhase,
    WorkoutType,
    RaceDistance,
)


class PlanRepository(Repository[TrainingPlan]):
    """
    SQLite-backed repository for TrainingPlan entities.

    Provides persistent storage for training plans generated by the plan agent,
    replacing in-memory storage with database persistence.
    """

    def __init__(self, db_path: Optional[str] = None):
        """
        Initialize the plan repository.

        Args:
            db_path: Path to SQLite database file. If None, uses the default
                    training.db in the training-analyzer directory.
        """
        if db_path:
            self.db_path = Path(db_path)
        else:
            import os
            env_path = os.environ.get("TRAINING_DB_PATH")
            if env_path:
                self.db_path = Path(env_path)
            else:
                self.db_path = Path(__file__).parent.parent.parent.parent.parent / "training.db"

        self._ensure_table_exists()

    @contextmanager
    def _get_connection(self):
        """Get database connection with context manager."""
        conn = sqlite3.connect(str(self.db_path))
        conn.row_factory = sqlite3.Row
        try:
            yield conn
            conn.commit()
        except Exception:
            conn.rollback()
            raise
        finally:
            conn.close()

    def _ensure_table_exists(self):
        """Ensure the training_plans table exists."""
        with self._get_connection() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS training_plans (
                    id TEXT PRIMARY KEY,
                    name TEXT,
                    description TEXT,
                    goal_json TEXT NOT NULL,
                    periodization TEXT NOT NULL,
                    peak_week INTEGER NOT NULL,
                    total_weeks INTEGER NOT NULL,
                    weeks_json TEXT NOT NULL,
                    athlete_context_json TEXT,
                    constraints_json TEXT,
                    phases_summary_json TEXT,
                    total_planned_load REAL,
                    is_active INTEGER DEFAULT 0,
                    adaptation_history_json TEXT,
                    created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_training_plans_created_at
                ON training_plans(created_at)
            """)
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_training_plans_is_active
                ON training_plans(is_active)
            """)

    def _plan_to_row(self, plan: TrainingPlan) -> dict:
        """Convert a TrainingPlan to a database row dictionary."""
        return {
            "id": plan.id,
            "name": plan.name,
            "description": plan.description,
            "goal_json": json.dumps(plan.goal.to_dict()),
            "periodization": plan.periodization.value,
            "peak_week": plan.peak_week,
            "total_weeks": plan.total_weeks,
            "weeks_json": json.dumps([w.to_dict() for w in plan.weeks]),
            "athlete_context_json": json.dumps(plan.athlete_context.to_dict()) if plan.athlete_context else None,
            "constraints_json": json.dumps(plan.constraints.to_dict()) if plan.constraints else None,
            "phases_summary_json": json.dumps(plan.phases_summary),
            "total_planned_load": plan.total_planned_load,
            "is_active": 1 if plan.is_active else 0,
            "adaptation_history_json": json.dumps(plan.adaptation_history) if plan.adaptation_history else None,
            "created_at": plan.created_at.isoformat() if plan.created_at else datetime.now().isoformat(),
            "updated_at": plan.updated_at.isoformat() if plan.updated_at else datetime.now().isoformat(),
        }

    def _row_to_plan(self, row: sqlite3.Row) -> TrainingPlan:
        """Convert a database row to a TrainingPlan."""
        # Parse goal
        goal_data = json.loads(row["goal_json"])
        goal = RaceGoal(
            race_date=datetime.strptime(goal_data["race_date"], "%Y-%m-%d").date(),
            distance=RaceDistance(goal_data["distance"]),
            target_time_seconds=goal_data["target_time_seconds"],
            race_name=goal_data.get("race_name"),
            priority=goal_data.get("priority", 1),
        )

        # Parse weeks
        weeks_data = json.loads(row["weeks_json"])
        weeks = []
        for week_data in weeks_data:
            sessions = []
            for session_data in week_data.get("sessions", []):
                sessions.append(PlannedSession(
                    day_of_week=session_data["day_of_week"],
                    workout_type=WorkoutType(session_data["workout_type"]),
                    description=session_data["description"],
                    target_duration_min=session_data["target_duration_min"],
                    target_load=session_data["target_load"],
                    target_pace=session_data.get("target_pace"),
                    target_hr_zone=session_data.get("target_hr_zone"),
                    intervals=session_data.get("intervals"),
                    notes=session_data.get("notes"),
                ))

            weeks.append(TrainingWeek(
                week_number=week_data["week_number"],
                phase=TrainingPhase(week_data["phase"]),
                target_load=week_data["target_load"],
                sessions=sessions,
                focus=week_data.get("focus"),
                notes=week_data.get("notes"),
                is_cutback=week_data.get("is_cutback", False),
            ))

        # Parse athlete context if available
        athlete_context = None
        if row["athlete_context_json"]:
            ac_data = json.loads(row["athlete_context_json"])
            athlete_context = AthleteContext(
                current_ctl=ac_data["current_ctl"],
                current_atl=ac_data["current_atl"],
                recent_weekly_load=ac_data["recent_weekly_load"],
                recent_weekly_hours=ac_data["recent_weekly_hours"],
                max_hr=ac_data.get("max_hr", 185),
                rest_hr=ac_data.get("rest_hr", 55),
                threshold_hr=ac_data.get("threshold_hr", 165),
                vdot=ac_data.get("vdot"),
            )

        # Parse constraints if available
        constraints = None
        if row["constraints_json"]:
            c_data = json.loads(row["constraints_json"])
            constraints = PlanConstraints(
                days_per_week=c_data["days_per_week"],
                long_run_day=c_data["long_run_day"],
                rest_days=c_data.get("rest_days", []),
                max_weekly_hours=c_data["max_weekly_hours"],
                max_session_duration_min=c_data.get("max_session_duration_min", 150),
                include_cross_training=c_data.get("include_cross_training", False),
                back_to_back_hard_ok=c_data.get("back_to_back_hard_ok", False),
            )

        # Parse timestamps
        created_at = row["created_at"]
        if isinstance(created_at, str):
            created_at = datetime.fromisoformat(created_at)

        updated_at = row["updated_at"]
        if updated_at and isinstance(updated_at, str):
            updated_at = datetime.fromisoformat(updated_at)

        # Parse adaptation history
        adaptation_history = []
        if row["adaptation_history_json"]:
            adaptation_history = json.loads(row["adaptation_history_json"])

        return TrainingPlan(
            id=row["id"],
            goal=goal,
            weeks=weeks,
            periodization=PeriodizationType(row["periodization"]),
            peak_week=row["peak_week"],
            created_at=created_at,
            athlete_context=athlete_context,
            constraints=constraints,
            name=row["name"],
            description=row["description"],
            is_active=bool(row["is_active"]),
            updated_at=updated_at,
            adaptation_history=adaptation_history,
        )

    def _plan_to_dict(self, plan: TrainingPlan) -> Dict[str, Any]:
        """Convert a TrainingPlan to a dictionary (for compatibility with routes)."""
        return plan.to_dict()

    def save(self, entity: TrainingPlan) -> TrainingPlan:
        """
        Save a training plan to the database.

        If the plan already exists (by ID), it will be updated.
        Otherwise, a new plan will be created.

        Args:
            entity: The plan to save

        Returns:
            The saved plan
        """
        # Update the updated_at timestamp
        entity.updated_at = datetime.now()

        row = self._plan_to_row(entity)

        with self._get_connection() as conn:
            conn.execute("""
                INSERT OR REPLACE INTO training_plans
                (id, name, description, goal_json, periodization, peak_week,
                 total_weeks, weeks_json, athlete_context_json, constraints_json,
                 phases_summary_json, total_planned_load, is_active,
                 adaptation_history_json, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                row["id"],
                row["name"],
                row["description"],
                row["goal_json"],
                row["periodization"],
                row["peak_week"],
                row["total_weeks"],
                row["weeks_json"],
                row["athlete_context_json"],
                row["constraints_json"],
                row["phases_summary_json"],
                row["total_planned_load"],
                row["is_active"],
                row["adaptation_history_json"],
                row["created_at"],
                row["updated_at"],
            ))

        return entity

    def save_dict(self, plan_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Save a plan from dictionary format (for backward compatibility with routes).

        Args:
            plan_data: The plan data as a dictionary

        Returns:
            The saved plan data as a dictionary
        """
        plan_data["updated_at"] = datetime.now().isoformat()

        with self._get_connection() as conn:
            # Extract and prepare JSON fields
            goal_json = json.dumps(plan_data["goal"])
            weeks_json = json.dumps(plan_data.get("weeks", []))
            athlete_context_json = json.dumps(plan_data["athlete_context"]) if plan_data.get("athlete_context") else None
            constraints_json = json.dumps(plan_data["constraints"]) if plan_data.get("constraints") else None
            phases_summary_json = json.dumps(plan_data.get("phases_summary", {}))
            adaptation_history_json = json.dumps(plan_data.get("adaptation_history", []))

            conn.execute("""
                INSERT OR REPLACE INTO training_plans
                (id, name, description, goal_json, periodization, peak_week,
                 total_weeks, weeks_json, athlete_context_json, constraints_json,
                 phases_summary_json, total_planned_load, is_active,
                 adaptation_history_json, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                plan_data["id"],
                plan_data.get("name"),
                plan_data.get("description"),
                goal_json,
                plan_data["periodization"],
                plan_data["peak_week"],
                plan_data["total_weeks"],
                weeks_json,
                athlete_context_json,
                constraints_json,
                phases_summary_json,
                plan_data.get("total_planned_load"),
                1 if plan_data.get("is_active") else 0,
                adaptation_history_json,
                plan_data["created_at"],
                plan_data["updated_at"],
            ))

        return plan_data

    def get(self, entity_id: str) -> Optional[TrainingPlan]:
        """
        Retrieve a training plan by its ID.

        Args:
            entity_id: The plan ID

        Returns:
            The plan if found, None otherwise
        """
        with self._get_connection() as conn:
            row = conn.execute(
                "SELECT * FROM training_plans WHERE id = ?",
                (entity_id,)
            ).fetchone()

            if row:
                return self._row_to_plan(row)
            return None

    def get_as_dict(self, entity_id: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve a training plan as a dictionary (for backward compatibility with routes).

        Args:
            entity_id: The plan ID

        Returns:
            The plan data as a dictionary if found, None otherwise
        """
        plan = self.get(entity_id)
        if plan:
            return self._plan_to_dict(plan)
        return None

    def get_all(
        self,
        limit: int = 100,
        offset: int = 0,
        **filters
    ) -> List[TrainingPlan]:
        """
        Retrieve all training plans matching the given filters.

        Args:
            limit: Maximum number of plans to return
            offset: Number of plans to skip
            **filters: Additional filter criteria:
                - active_only: If True, only return active plans
                - periodization: Filter by periodization type

        Returns:
            List of matching plans, ordered by creation time (newest first)
        """
        query = "SELECT * FROM training_plans WHERE 1=1"
        params = []

        if filters.get("active_only"):
            query += " AND is_active = 1"

        if "periodization" in filters:
            query += " AND periodization = ?"
            params.append(filters["periodization"])

        query += " ORDER BY created_at DESC LIMIT ? OFFSET ?"
        params.extend([limit, offset])

        with self._get_connection() as conn:
            rows = conn.execute(query, params).fetchall()
            return [self._row_to_plan(row) for row in rows]

    def get_all_as_dicts(
        self,
        limit: int = 100,
        offset: int = 0,
        **filters
    ) -> List[Dict[str, Any]]:
        """
        Retrieve all training plans as dictionaries (for backward compatibility with routes).

        Args:
            limit: Maximum number of plans to return
            offset: Number of plans to skip
            **filters: Additional filter criteria

        Returns:
            List of matching plan data as dictionaries
        """
        plans = self.get_all(limit=limit, offset=offset, **filters)
        return [self._plan_to_dict(p) for p in plans]

    def delete(self, entity_id: str) -> bool:
        """
        Delete a training plan by its ID.

        Args:
            entity_id: The plan ID to delete

        Returns:
            True if the plan was deleted, False if not found
        """
        with self._get_connection() as conn:
            cursor = conn.execute(
                "DELETE FROM training_plans WHERE id = ?",
                (entity_id,)
            )
            return cursor.rowcount > 0

    def exists(self, entity_id: str) -> bool:
        """
        Check if a training plan exists by its ID.

        Args:
            entity_id: The plan ID to check

        Returns:
            True if the plan exists, False otherwise
        """
        with self._get_connection() as conn:
            row = conn.execute(
                "SELECT 1 FROM training_plans WHERE id = ?",
                (entity_id,)
            ).fetchone()
            return row is not None

    def count(self, **filters) -> int:
        """
        Count training plans matching the given filters.

        Args:
            **filters: Filter criteria (same as get_all)

        Returns:
            Number of matching plans
        """
        query = "SELECT COUNT(*) as cnt FROM training_plans WHERE 1=1"
        params = []

        if filters.get("active_only"):
            query += " AND is_active = 1"

        if "periodization" in filters:
            query += " AND periodization = ?"
            params.append(filters["periodization"])

        with self._get_connection() as conn:
            row = conn.execute(query, params).fetchone()
            return row["cnt"]

    def get_active(self) -> Optional[TrainingPlan]:
        """
        Get the currently active training plan.

        Returns:
            The active plan if one exists, None otherwise
        """
        with self._get_connection() as conn:
            row = conn.execute("""
                SELECT * FROM training_plans
                WHERE is_active = 1
                ORDER BY created_at DESC
                LIMIT 1
            """).fetchone()

            if row:
                return self._row_to_plan(row)
            return None

    def set_active(self, plan_id: str) -> bool:
        """
        Set a plan as the active training plan.

        Deactivates all other plans first.

        Args:
            plan_id: The plan ID to activate

        Returns:
            True if successful, False if plan not found
        """
        with self._get_connection() as conn:
            # Check if plan exists
            row = conn.execute(
                "SELECT 1 FROM training_plans WHERE id = ?",
                (plan_id,)
            ).fetchone()

            if not row:
                return False

            # Deactivate all plans
            conn.execute("UPDATE training_plans SET is_active = 0")

            # Activate the specified plan
            conn.execute(
                "UPDATE training_plans SET is_active = 1, updated_at = ? WHERE id = ?",
                (datetime.now().isoformat(), plan_id)
            )

            return True

    def deactivate_all(self) -> int:
        """
        Deactivate all training plans.

        Returns:
            Number of plans deactivated
        """
        with self._get_connection() as conn:
            cursor = conn.execute(
                "UPDATE training_plans SET is_active = 0, updated_at = ? WHERE is_active = 1",
                (datetime.now().isoformat(),)
            )
            return cursor.rowcount

    def get_upcoming(self, limit: int = 5) -> List[TrainingPlan]:
        """
        Get plans with upcoming race dates.

        Args:
            limit: Maximum number of plans to return

        Returns:
            List of plans with future race dates
        """
        today = date.today().isoformat()
        with self._get_connection() as conn:
            rows = conn.execute("""
                SELECT * FROM training_plans
                WHERE json_extract(goal_json, '$.race_date') >= ?
                ORDER BY json_extract(goal_json, '$.race_date') ASC
                LIMIT ?
            """, (today, limit)).fetchall()
            return [self._row_to_plan(row) for row in rows]


# Singleton instance for dependency injection
_plan_repository: Optional[PlanRepository] = None


def get_plan_repository() -> PlanRepository:
    """Get or create the singleton PlanRepository instance."""
    global _plan_repository
    if _plan_repository is None:
        _plan_repository = PlanRepository()
    return _plan_repository
